{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header_cell",
            "metadata": {},
            "source": [
                "# Week 1: Introduction to MLOps & Version Control\n",
                "\n",
                "## üìö Notebook Overview\n",
                "This notebook demonstrates a complete Machine Learning pipeline using the Iris dataset.\n",
                "\n",
                "**Key Concepts Covered:**\n",
                "- Data loading and preprocessing\n",
                "- Feature engineering\n",
                "- Model training with RandomForest\n",
                "- Hyperparameter tuning with Hyperopt (TPE algorithm)\n",
                "- Model evaluation\n",
                "- Scikit-learn Pipelines for reproducibility\n",
                "\n",
                "**Dataset:** Iris Dataset (150 samples, 4 features, 3 classes)\n",
                "- Features: Sepal Length, Sepal Width, Petal Length, Petal Width\n",
                "- Target: Species (Setosa, Versicolor, Virginica)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "729276b3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\conda\\envs\\lc_agent\\Lib\\site-packages\\hyperopt\\atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
                        "  import pkg_resources\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# IMPORT LIBRARIES\n",
                "# ============================================================================\n",
                "#    \n",
                "# Data manipulation and analysis\n",
                "import pandas as pd  # For loading and manipulating tabular data (DataFrames)\n",
                "\n",
                "# Scikit-learn: Machine Learning library\n",
                "from sklearn.model_selection import train_test_split  # Split data into train/test sets\n",
                "from sklearn.model_selection import cross_val_score   # Perform k-fold cross-validation\n",
                "from sklearn.ensemble import RandomForestClassifier   # Random Forest algorithm for classification\n",
                "from sklearn.metrics import accuracy_score            # Calculate accuracy metric\n",
                "\n",
                "# Hyperopt: Hyperparameter optimization library\n",
                "from hyperopt import fmin      # Function minimization (optimization)\n",
                "from hyperopt import tpe       # Tree of Parzen Estimators algorithm (smart search)\n",
                "from hyperopt import hp        # Define hyperparameter search spaces\n",
                "\n",
                "# Scikit-learn Pipeline components for building reproducible ML workflows\n",
                "from sklearn.pipeline import Pipeline              # Create sequential transformation pipeline\n",
                "from sklearn.compose import ColumnTransformer      # Apply different transformations to different columns\n",
                "from sklearn.preprocessing import StandardScaler   # Standardize features (mean=0, std=1)\n",
                "from sklearn.impute import SimpleImputer           # Handle missing values (not used in this example)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "functions_header",
            "metadata": {},
            "source": [
                "## üîß Helper Functions\n",
                "\n",
                "These modular functions make our code:\n",
                "- **Reusable**: Can be called multiple times\n",
                "- **Testable**: Each function can be tested independently\n",
                "- **Maintainable**: Easy to update and debug\n",
                "- **Production-ready**: Follows software engineering best practices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "f6e31911",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# FUNCTION 1: READ CSV FILE\n",
                "# ============================================================================\n",
                "def read_csv(file_path):\n",
                "    \"\"\"\n",
                "    Load data from a CSV file into a pandas DataFrame.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    file_path : str\n",
                "        Path to the CSV file (relative or absolute)\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    pd.DataFrame\n",
                "        Loaded data as a pandas DataFrame\n",
                "    \n",
                "    Example:\n",
                "    --------\n",
                "    >>> data = read_csv('Iris.csv')\n",
                "    \"\"\"\n",
                "    # pd.read_csv() reads CSV files and automatically infers data types\n",
                "    return pd.read_csv(file_path)\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# FUNCTION 2: CREATE FEATURES (FEATURE ENGINEERING)\n",
                "# ============================================================================\n",
                "def create_features(data):\n",
                "    \"\"\"\n",
                "    Perform feature engineering on the dataset.\n",
                "    \n",
                "    Feature engineering is the process of creating new features from existing ones\n",
                "    to improve model performance. Examples include:\n",
                "    - Creating interaction features (e.g., sepal_length * sepal_width)\n",
                "    - Polynomial features (e.g., sepal_length^2)\n",
                "    - Binning continuous variables\n",
                "    - Encoding categorical variables\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    data : pd.DataFrame\n",
                "        Input dataset\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    pd.DataFrame\n",
                "        Dataset with engineered features\n",
                "    \n",
                "    Note:\n",
                "    -----\n",
                "    For this Iris dataset example, we don't create additional features\n",
                "    because the original 4 features are already highly predictive.\n",
                "    In real-world scenarios, feature engineering is crucial for model performance.\n",
                "    \"\"\"\n",
                "    # No feature creation for this simple example\n",
                "    # The Iris dataset's original features are sufficient for classification\n",
                "    return data\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# FUNCTION 3: TRAIN CLASSIFIER MODEL\n",
                "# ============================================================================\n",
                "def train_classifier(data):\n",
                "    \"\"\"\n",
                "    Train a Random Forest classifier on the provided data.\n",
                "    \n",
                "    This function performs:\n",
                "    1. Train-test split (80-20 split)\n",
                "    2. Model initialization\n",
                "    3. Model training\n",
                "    4. Prediction on test set\n",
                "    5. Accuracy calculation\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    data : Not used directly (uses global X, y variables)\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    tuple\n",
                "        (trained_model, accuracy_score)\n",
                "    \n",
                "    Note:\n",
                "    -----\n",
                "    This function assumes X and y are defined globally.\n",
                "    In production, you should pass X and y as parameters.\n",
                "    \"\"\"\n",
                "    # Split data into training (80%) and testing (20%) sets\n",
                "    # random_state=42 ensures reproducibility (same split every time)\n",
                "    # X_train: Features for training\n",
                "    # X_test: Features for testing\n",
                "    # y_train: Target labels for training\n",
                "    # y_test: Target labels for testing\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X,                    # Feature matrix\n",
                "        y,                    # Target vector\n",
                "        test_size=0.2,        # 20% of data for testing\n",
                "        random_state=42       # Seed for reproducibility\n",
                "    )\n",
                "\n",
                "    # Initialize Random Forest Classifier with default parameters\n",
                "    # Random Forest is an ensemble method that builds multiple decision trees\n",
                "    # and combines their predictions (voting for classification)\n",
                "    # Default parameters: n_estimators=100, max_depth=None, etc.\n",
                "    model = RandomForestClassifier()\n",
                "    \n",
                "    # Train the model on training data\n",
                "    # .fit() learns patterns from X_train to predict y_train\n",
                "    model.fit(X_train, y_train)\n",
                "\n",
                "    # Make predictions on the test set\n",
                "    # .predict() uses the trained model to predict labels for X_test\n",
                "    y_pred = model.predict(X_test)\n",
                "    \n",
                "    # Calculate accuracy: (correct predictions / total predictions)\n",
                "    # Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "\n",
                "    # Return both the trained model and its accuracy\n",
                "    return model, accuracy\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# FUNCTION 4: OBJECTIVE FUNCTION FOR HYPERPARAMETER TUNING\n",
                "# ============================================================================\n",
                "def objective(params):\n",
                "    \"\"\"\n",
                "    Objective function for Hyperopt optimization.\n",
                "    \n",
                "    This function is called by Hyperopt's optimization algorithm (TPE)\n",
                "    to evaluate different hyperparameter combinations.\n",
                "    \n",
                "    How it works:\n",
                "    1. Receives a set of hyperparameters from Hyperopt\n",
                "    2. Trains a model with those hyperparameters\n",
                "    3. Evaluates the model using cross-validation\n",
                "    4. Returns a score (lower is better for fmin)\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    params : dict\n",
                "        Dictionary of hyperparameters to test\n",
                "        Example: {'n_estimators': 50, 'max_depth': 10}\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    float\n",
                "        Negative mean cross-validation accuracy\n",
                "        (negative because fmin minimizes, but we want to maximize accuracy)\n",
                "    \n",
                "    Note:\n",
                "    -----\n",
                "    Cross-validation provides a more robust estimate of model performance\n",
                "    than a single train-test split.\n",
                "    \"\"\"\n",
                "    # Create a Random Forest model with the hyperparameters provided by Hyperopt\n",
                "    # **params unpacks the dictionary: {'n_estimators': 50} -> n_estimators=50\n",
                "    model = RandomForestClassifier(**params)\n",
                "    \n",
                "    # Perform 5-fold cross-validation\n",
                "    # Cross-validation splits data into 5 parts:\n",
                "    # - Train on 4 parts, validate on 1 part\n",
                "    # - Repeat 5 times (each part used as validation once)\n",
                "    # - Returns 5 accuracy scores\n",
                "    # .mean() calculates the average of these 5 scores\n",
                "    score = cross_val_score(\n",
                "        model,      # Model to evaluate\n",
                "        X,          # Feature matrix\n",
                "        y,          # Target vector\n",
                "        cv=5        # Number of folds (5-fold cross-validation)\n",
                "    ).mean()        # Average accuracy across all folds\n",
                "    \n",
                "    # Return negative score because fmin() MINIMIZES the objective function\n",
                "    # We want to MAXIMIZE accuracy, so we minimize negative accuracy\n",
                "    # Example: accuracy=0.95 -> return -0.95 (lower is better for fmin)\n",
                "    return -score\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# FUNCTION 5: EVALUATE MODEL ON TEST SET\n",
                "# ============================================================================\n",
                "def evaluate_model(model, X_test, y_test):\n",
                "    \"\"\"\n",
                "    Evaluate a trained model on the test set.\n",
                "    \n",
                "    This function provides the final performance metric on unseen data.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    model : sklearn estimator\n",
                "        Trained machine learning model\n",
                "    X_test : pd.DataFrame or np.array\n",
                "        Test features\n",
                "    y_test : pd.Series or np.array\n",
                "        True labels for test set\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    float\n",
                "        Accuracy score (0.0 to 1.0)\n",
                "    \n",
                "    Example:\n",
                "    --------\n",
                "    >>> accuracy = evaluate_model(model, X_test, y_test)\n",
                "    >>> print(f\"Test Accuracy: {accuracy:.2%}\")  # Output: Test Accuracy: 96.67%\n",
                "    \"\"\"\n",
                "    # Make predictions on the test set\n",
                "    y_pred = model.predict(X_test)\n",
                "    \n",
                "    # Calculate and return accuracy\n",
                "    # Accuracy = (Number of correct predictions) / (Total predictions)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    \n",
                "    return accuracy"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_loading_header",
            "metadata": {},
            "source": [
                "## üìä Data Loading\n",
                "\n",
                "Loading the Iris dataset from CSV file.\n",
                "\n",
                "**Note:** The file path has been updated to use the correct location (`Iris.csv` in the current directory)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "3319d235",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset loaded successfully!\n",
                        "Shape: (150, 6)\n",
                        "\n",
                        "First 5 rows:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Id</th>\n",
                            "      <th>SepalLengthCm</th>\n",
                            "      <th>SepalWidthCm</th>\n",
                            "      <th>PetalLengthCm</th>\n",
                            "      <th>PetalWidthCm</th>\n",
                            "      <th>Species</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>5.1</td>\n",
                            "      <td>3.5</td>\n",
                            "      <td>1.4</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>4.9</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>1.4</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>4.7</td>\n",
                            "      <td>3.2</td>\n",
                            "      <td>1.3</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>4.6</td>\n",
                            "      <td>3.1</td>\n",
                            "      <td>1.5</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>3.6</td>\n",
                            "      <td>1.4</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
                            "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
                            "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
                            "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
                            "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
                            "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# LOAD DATA FROM CSV FILE\n",
                "# ============================================================================\n",
                "\n",
                "# Define the file path to the Iris dataset\n",
                "# Using relative path: file is in the same directory as this notebook\n",
                "file_path = \"Iris.csv\"\n",
                "\n",
                "# Load the CSV file into a pandas DataFrame using our custom function\n",
                "# This reads the entire dataset into memory\n",
                "data = read_csv(file_path)\n",
                "\n",
                "# Display the first few rows to verify data loaded correctly\n",
                "print(\"Dataset loaded successfully!\")\n",
                "print(f\"Shape: {data.shape}\")  # (rows, columns)\n",
                "print(f\"\\nFirst 5 rows:\")\n",
                "data.head()  # Shows first 5 rows by default"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_exploration_header",
            "metadata": {},
            "source": [
                "## üîç Data Exploration\n",
                "\n",
                "Let's examine the dataset structure and contents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "data_exploration",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset Information:\n",
                        "==================================================\n",
                        "Number of samples (rows): 150\n",
                        "Number of features (columns): 6\n",
                        "\n",
                        "Column names: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
                        "\n",
                        "Missing values per column:\n",
                        "Id               0\n",
                        "SepalLengthCm    0\n",
                        "SepalWidthCm     0\n",
                        "PetalLengthCm    0\n",
                        "PetalWidthCm     0\n",
                        "Species          0\n",
                        "dtype: int64\n",
                        "\n",
                        "Class distribution:\n",
                        "Species\n",
                        "Iris-setosa        50\n",
                        "Iris-versicolor    50\n",
                        "Iris-virginica     50\n",
                        "Name: count, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Id</th>\n",
                            "      <th>SepalLengthCm</th>\n",
                            "      <th>SepalWidthCm</th>\n",
                            "      <th>PetalLengthCm</th>\n",
                            "      <th>PetalWidthCm</th>\n",
                            "      <th>Species</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>5.1</td>\n",
                            "      <td>3.5</td>\n",
                            "      <td>1.4</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>4.9</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>1.4</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>4.7</td>\n",
                            "      <td>3.2</td>\n",
                            "      <td>1.3</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>4.6</td>\n",
                            "      <td>3.1</td>\n",
                            "      <td>1.5</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>3.6</td>\n",
                            "      <td>1.4</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>Iris-setosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>145</th>\n",
                            "      <td>146</td>\n",
                            "      <td>6.7</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>5.2</td>\n",
                            "      <td>2.3</td>\n",
                            "      <td>Iris-virginica</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>146</th>\n",
                            "      <td>147</td>\n",
                            "      <td>6.3</td>\n",
                            "      <td>2.5</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>1.9</td>\n",
                            "      <td>Iris-virginica</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>147</th>\n",
                            "      <td>148</td>\n",
                            "      <td>6.5</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>5.2</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>Iris-virginica</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>148</th>\n",
                            "      <td>149</td>\n",
                            "      <td>6.2</td>\n",
                            "      <td>3.4</td>\n",
                            "      <td>5.4</td>\n",
                            "      <td>2.3</td>\n",
                            "      <td>Iris-virginica</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>149</th>\n",
                            "      <td>150</td>\n",
                            "      <td>5.9</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>5.1</td>\n",
                            "      <td>1.8</td>\n",
                            "      <td>Iris-virginica</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>150 rows √ó 6 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
                            "0      1            5.1           3.5            1.4           0.2   \n",
                            "1      2            4.9           3.0            1.4           0.2   \n",
                            "2      3            4.7           3.2            1.3           0.2   \n",
                            "3      4            4.6           3.1            1.5           0.2   \n",
                            "4      5            5.0           3.6            1.4           0.2   \n",
                            "..   ...            ...           ...            ...           ...   \n",
                            "145  146            6.7           3.0            5.2           2.3   \n",
                            "146  147            6.3           2.5            5.0           1.9   \n",
                            "147  148            6.5           3.0            5.2           2.0   \n",
                            "148  149            6.2           3.4            5.4           2.3   \n",
                            "149  150            5.9           3.0            5.1           1.8   \n",
                            "\n",
                            "            Species  \n",
                            "0       Iris-setosa  \n",
                            "1       Iris-setosa  \n",
                            "2       Iris-setosa  \n",
                            "3       Iris-setosa  \n",
                            "4       Iris-setosa  \n",
                            "..              ...  \n",
                            "145  Iris-virginica  \n",
                            "146  Iris-virginica  \n",
                            "147  Iris-virginica  \n",
                            "148  Iris-virginica  \n",
                            "149  Iris-virginica  \n",
                            "\n",
                            "[150 rows x 6 columns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# EXPLORE THE DATASET\n",
                "# ============================================================================\n",
                "\n",
                "# Display basic information about the dataset\n",
                "print(\"Dataset Information:\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Show dataset dimensions\n",
                "print(f\"Number of samples (rows): {data.shape[0]}\")\n",
                "print(f\"Number of features (columns): {data.shape[1]}\")\n",
                "\n",
                "# Show column names and data types\n",
                "print(f\"\\nColumn names: {list(data.columns)}\")\n",
                "\n",
                "# Check for missing values\n",
                "print(f\"\\nMissing values per column:\")\n",
                "print(data.isnull().sum())\n",
                "\n",
                "# Show class distribution (how many samples per species)\n",
                "print(f\"\\nClass distribution:\")\n",
                "print(data['Species'].value_counts())\n",
                "\n",
                "# Display the full dataset\n",
                "data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pipeline_header",
            "metadata": {},
            "source": [
                "## üîÑ ML Pipeline Implementation\n",
                "\n",
                "Building a complete machine learning pipeline with:\n",
                "1. **Data Preprocessing**: Feature scaling\n",
                "2. **Model Training**: Random Forest Classifier\n",
                "3. **Hyperparameter Tuning**: Hyperopt with TPE algorithm\n",
                "\n",
                "### Why Use Pipelines?\n",
                "- **Reproducibility**: Same transformations applied consistently\n",
                "- **Prevents Data Leakage**: Ensures test data isn't used in training\n",
                "- **Simplifies Deployment**: Single object contains all steps\n",
                "- **Easy to Version Control**: Entire workflow in one object"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "main_pipeline",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature matrix (X) shape: (150, 4)\n",
                        "Target vector (y) shape: (150,)\n",
                        "\n",
                        "Feature columns: ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
                        "\n",
                        "Training set size: 120 samples\n",
                        "Test set size: 30 samples\n",
                        "\n",
                        "Pipeline created successfully!\n",
                        "Pipeline steps:\n",
                        "  - preprocessor: ColumnTransformer\n",
                        "  - classifier: RandomForestClassifier\n",
                        "\n",
                        "Training the model...\n",
                        "Training complete!\n",
                        "\n",
                        "==================================================\n",
                        "MODEL EVALUATION RESULTS\n",
                        "==================================================\n",
                        "Model accuracy on test set: 1.0000 (100.00%)\n",
                        "Correct predictions: 30/30\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# MAIN PIPELINE EXECUTION\n",
                "# ============================================================================\n",
                "\n",
                "# Step 1: Apply feature engineering (if any)\n",
                "# ----------------------------------------\n",
                "# In this case, no new features are created, but this step is included\n",
                "# to demonstrate a complete ML workflow\n",
                "data = create_features(data)\n",
                "\n",
                "\n",
                "# Step 2: Prepare Features (X) and Target (y)\n",
                "# ----------------------------------------\n",
                "# Separate the dataset into:\n",
                "# - X: Feature matrix (all columns except 'Species' and 'Id')\n",
                "# - y: Target vector (only 'Species' column)\n",
                "\n",
                "# Drop 'Species' (target) and 'Id' (not a feature) columns to create feature matrix\n",
                "# axis=1 means drop columns (axis=0 would drop rows)\n",
                "X = data.drop(['Species', 'Id'], axis=1)\n",
                "\n",
                "# Extract only the 'Species' column as the target variable\n",
                "y = data['Species']\n",
                "\n",
                "# Display shapes to verify correct separation\n",
                "print(f\"Feature matrix (X) shape: {X.shape}\")  # Should be (150, 4)\n",
                "print(f\"Target vector (y) shape: {y.shape}\")   # Should be (150,)\n",
                "print(f\"\\nFeature columns: {list(X.columns)}\")\n",
                "\n",
                "\n",
                "# Step 3: Split Data into Training and Test Sets\n",
                "# ----------------------------------------\n",
                "# Split ratio: 80% training, 20% testing\n",
                "# random_state=42 ensures the same split every time (reproducibility)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X,                    # Feature matrix\n",
                "    y,                    # Target vector\n",
                "    test_size=0.2,        # 20% of data reserved for testing (30 samples)\n",
                "    random_state=42       # Seed for reproducibility\n",
                ")\n",
                "\n",
                "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")  # 120 samples\n",
                "print(f\"Test set size: {X_test.shape[0]} samples\")        # 30 samples\n",
                "\n",
                "\n",
                "# Step 4: Define the ML Pipeline\n",
                "# ----------------------------------------\n",
                "# A pipeline chains multiple steps together:\n",
                "# 1. Preprocessing (StandardScaler)\n",
                "# 2. Model (RandomForestClassifier)\n",
                "\n",
                "pipeline = Pipeline([\n",
                "    # First step: Preprocessing\n",
                "    # ColumnTransformer allows different transformations for different columns\n",
                "    ('preprocessor', ColumnTransformer(\n",
                "        transformers=[\n",
                "            # Apply StandardScaler to all numeric columns\n",
                "            # StandardScaler: transforms features to have mean=0 and std=1\n",
                "            # Formula: z = (x - mean) / std\n",
                "            # This ensures all features are on the same scale\n",
                "            ('num', StandardScaler(), X.columns)\n",
                "        ],\n",
                "        # 'passthrough' means any columns not specified are passed unchanged\n",
                "        remainder='passthrough'\n",
                "    )),\n",
                "    \n",
                "    # Second step: Classification model\n",
                "    # RandomForestClassifier with default hyperparameters\n",
                "    # Default: n_estimators=100, max_depth=None, min_samples_split=2, etc.\n",
                "    ('classifier', RandomForestClassifier())\n",
                "])\n",
                "\n",
                "print(\"\\nPipeline created successfully!\")\n",
                "print(\"Pipeline steps:\")\n",
                "for step_name, step_obj in pipeline.steps:\n",
                "    print(f\"  - {step_name}: {type(step_obj).__name__}\")\n",
                "\n",
                "\n",
                "# Step 5: Train the Pipeline\n",
                "# ----------------------------------------\n",
                "# .fit() trains the entire pipeline:\n",
                "# 1. Fits StandardScaler on X_train (calculates mean and std)\n",
                "# 2. Transforms X_train using the fitted scaler\n",
                "# 3. Trains RandomForest on the scaled data\n",
                "print(\"\\nTraining the model...\")\n",
                "pipeline.fit(X_train, y_train)\n",
                "print(\"Training complete!\")\n",
                "\n",
                "\n",
                "# Step 6: Make Predictions on Test Set\n",
                "# ----------------------------------------\n",
                "# .predict() applies the entire pipeline:\n",
                "# 1. Scales X_test using the SAME scaler fitted on X_train\n",
                "# 2. Makes predictions using the trained RandomForest\n",
                "y_pred = pipeline.predict(X_test)\n",
                "\n",
                "\n",
                "# Step 7: Evaluate Model Performance\n",
                "# ----------------------------------------\n",
                "# Calculate accuracy: percentage of correct predictions\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "\n",
                "# Display results\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"MODEL EVALUATION RESULTS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Model accuracy on test set: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
                "print(f\"Correct predictions: {int(accuracy * len(y_test))}/{len(y_test)}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "hyperopt_header",
            "metadata": {},
            "source": [
                "## üéØ Hyperparameter Tuning with Hyperopt\n",
                "\n",
                "### What is Hyperparameter Tuning?\n",
                "Hyperparameters are settings that control the learning process (e.g., number of trees, tree depth).\n",
                "Unlike model parameters (learned from data), hyperparameters must be set before training.\n",
                "\n",
                "### Why Use Hyperopt?\n",
                "- **Smarter than Grid Search**: Uses Bayesian optimization (learns from previous trials)\n",
                "- **Faster**: Doesn't try every combination\n",
                "- **TPE Algorithm**: Tree of Parzen Estimators - models P(x|y) and P(y)\n",
                "\n",
                "### Hyperparameters We're Tuning:\n",
                "1. **n_estimators**: Number of trees in the forest (10-100)\n",
                "2. **max_depth**: Maximum depth of each tree (1-20)\n",
                "\n",
                "### Alternative Approach (Commented):\n",
                "Brute force with nested loops would try ALL combinations:\n",
                "- 91 values for n_estimators √ó 20 values for max_depth = 1,820 combinations!\n",
                "- Hyperopt intelligently samples the space, trying ~100 combinations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "hyperopt_tuning",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting Hyperparameter Optimization...\n",
                        "==================================================\n",
                        "Search space defined:\n",
                        "  - n_estimators: 10 to 100 (91 possible values)\n",
                        "  - max_depth: 1 to 20 (20 possible values)\n",
                        "  - Total combinations: 91 √ó 20 = 1,820\n",
                        "  - Hyperopt will intelligently sample ~100 combinations\n",
                        "\n",
                        "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:50<00:00,  2.00trial/s, best loss: -0.9666666666666668]\n",
                        "\n",
                        "==================================================\n",
                        "OPTIMIZATION COMPLETE!\n",
                        "==================================================\n",
                        "Best hyperparameters found:\n",
                        "  - n_estimators: 43\n",
                        "  - max_depth: 12\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# HYPERPARAMETER TUNING WITH HYPEROPT\n",
                "# ============================================================================\n",
                "\n",
                "# Note: Brute force approach (commented below) would be:\n",
                "# for n_est in range(10, 101):           # 91 values\n",
                "#     for max_d in range(1, 21):         # 20 values\n",
                "#         # Train and evaluate model     # Total: 91 √ó 20 = 1,820 iterations!\n",
                "# This is computationally expensive and inefficient.\n",
                "\n",
                "print(\"Starting Hyperparameter Optimization...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Define the search space for hyperparameters\n",
                "# ----------------------------------------\n",
                "# hp.choice() samples from a discrete list of values\n",
                "# range(10, 101) creates [10, 11, 12, ..., 100]\n",
                "space = {\n",
                "    # Number of trees in the forest: try values from 10 to 100\n",
                "    # More trees generally improve performance but increase training time\n",
                "    'n_estimators': hp.choice('n_estimators', range(10, 101)),\n",
                "    \n",
                "    # Maximum depth of each tree: try values from 1 to 20\n",
                "    # Deeper trees can model complex patterns but may overfit\n",
                "    # Shallower trees are simpler but may underfit\n",
                "    'max_depth': hp.choice('max_depth', range(1, 21))\n",
                "}\n",
                "\n",
                "print(\"Search space defined:\")\n",
                "print(f\"  - n_estimators: 10 to 100 (91 possible values)\")\n",
                "print(f\"  - max_depth: 1 to 20 (20 possible values)\")\n",
                "print(f\"  - Total combinations: 91 √ó 20 = 1,820\")\n",
                "print(f\"  - Hyperopt will intelligently sample ~100 combinations\\n\")\n",
                "\n",
                "# Run Hyperopt optimization\n",
                "# ----------------------------------------\n",
                "# fmin() finds the hyperparameters that MINIMIZE the objective function\n",
                "best_params = fmin(\n",
                "    fn=objective,           # Function to minimize (our objective function)\n",
                "    space=space,            # Hyperparameter search space defined above\n",
                "    algo=tpe.suggest,       # Algorithm: Tree of Parzen Estimators (TPE)\n",
                "                            # TPE is a Bayesian optimization algorithm that:\n",
                "                            # 1. Tries random combinations initially\n",
                "                            # 2. Learns which regions of hyperparameter space work well\n",
                "                            # 3. Focuses search on promising regions\n",
                "    max_evals=100           # Maximum number of hyperparameter combinations to try\n",
                "                            # More evaluations = better results but longer runtime\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"OPTIMIZATION COMPLETE!\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Best hyperparameters found:\")\n",
                "print(f\"  - n_estimators: {best_params['n_estimators']}\")\n",
                "print(f\"  - max_depth: {best_params['max_depth']}\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Note: The best_params values are indices from hp.choice()\n",
                "# They represent the actual values from our range() objects"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "best_params_header",
            "metadata": {},
            "source": [
                "## üìã Display Best Hyperparameters\n",
                "\n",
                "Let's examine the optimal hyperparameters found by Hyperopt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "b184a0cd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimal Hyperparameters:\n",
                        "{'max_depth': 12, 'n_estimators': 43}\n",
                        "\n",
                        "Interpretation:\n",
                        "  - The Random Forest should use 43 trees\n",
                        "  - Each tree should have a maximum depth of 12\n",
                        "\n",
                        "These values were found to give the best cross-validation accuracy.\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# DISPLAY BEST HYPERPARAMETERS\n",
                "# ============================================================================\n",
                "\n",
                "# Show the best hyperparameters found by Hyperopt\n",
                "# This dictionary contains the optimal values for n_estimators and max_depth\n",
                "print(\"Optimal Hyperparameters:\")\n",
                "print(best_params)\n",
                "\n",
                "# Additional information about what these values mean\n",
                "print(\"\\nInterpretation:\")\n",
                "print(f\"  - The Random Forest should use {best_params['n_estimators']} trees\")\n",
                "print(f\"  - Each tree should have a maximum depth of {best_params['max_depth']}\")\n",
                "print(\"\\nThese values were found to give the best cross-validation accuracy.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "retrain_header",
            "metadata": {},
            "source": [
                "## üîÑ Retrain Model with Optimized Hyperparameters\n",
                "\n",
                "Now that we have the best hyperparameters, let's train a new model and compare performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "retrain_model",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Retraining model with optimized hyperparameters...\n",
                        "==================================================\n",
                        "\n",
                        "==================================================\n",
                        "PERFORMANCE COMPARISON\n",
                        "==================================================\n",
                        "Default hyperparameters accuracy:   1.0000 (100.00%)\n",
                        "Optimized hyperparameters accuracy: 1.0000 (100.00%)\n",
                        "\n",
                        "Improvement: 0.00 percentage points\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "# ============================================================================\n",
                "# RETRAIN MODEL WITH BEST HYPERPARAMETERS\n",
                "# ============================================================================\n",
                "\n",
                "print(\"Retraining model with optimized hyperparameters...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Create a new pipeline with optimized hyperparameters\n",
                "# ----------------------------------------\n",
                "optimized_pipeline = Pipeline([\n",
                "    # Same preprocessing step as before\n",
                "    ('preprocessor', ColumnTransformer(\n",
                "        transformers=[\n",
                "            ('num', StandardScaler(), X.columns)\n",
                "        ],\n",
                "        remainder='passthrough'\n",
                "    )),\n",
                "    \n",
                "    # Updated classifier with BEST hyperparameters from Hyperopt\n",
                "    # **best_params unpacks the dictionary into keyword arguments\n",
                "    ('classifier', RandomForestClassifier(**best_params, random_state=42))\n",
                "])\n",
                "\n",
                "# Train the optimized pipeline\n",
                "# ----------------------------------------\n",
                "optimized_pipeline.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions with optimized model\n",
                "# ----------------------------------------\n",
                "y_pred_optimized = optimized_pipeline.predict(X_test)\n",
                "\n",
                "# Evaluate optimized model\n",
                "# ----------------------------------------\n",
                "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
                "\n",
                "# Display comparison\n",
                "# ----------------------------------------\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PERFORMANCE COMPARISON\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Default hyperparameters accuracy:   {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
                "print(f\"Optimized hyperparameters accuracy: {accuracy_optimized:.4f} ({accuracy_optimized*100:.2f}%)\")\n",
                "print(f\"\\nImprovement: {(accuracy_optimized - accuracy)*100:.2f} percentage points\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Note: For the Iris dataset, both models may achieve 100% accuracy\n",
                "# because it's a relatively simple classification problem.\n",
                "# Hyperparameter tuning shows more significant improvements on complex datasets."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary_header",
            "metadata": {},
            "source": [
                "## üìä Summary and Key Takeaways\n",
                "\n",
                "### What We Accomplished:\n",
                "1. ‚úÖ Loaded and explored the Iris dataset\n",
                "2. ‚úÖ Built a reproducible ML pipeline with preprocessing and modeling\n",
                "3. ‚úÖ Trained a Random Forest classifier\n",
                "4. ‚úÖ Performed hyperparameter tuning using Hyperopt (TPE algorithm)\n",
                "5. ‚úÖ Compared default vs. optimized model performance\n",
                "\n",
                "### MLOps Best Practices Demonstrated:\n",
                "- **Modularity**: Functions for each step (reusable, testable)\n",
                "- **Reproducibility**: Fixed random seeds, version-controlled code\n",
                "- **Pipelines**: Prevents data leakage, simplifies deployment\n",
                "- **Automation**: Hyperparameter tuning instead of manual search\n",
                "- **Documentation**: Comprehensive comments and markdown cells\n",
                "\n",
                "### Next Steps in MLOps Journey:\n",
                "- Version control this notebook with Git\n",
                "- Experiment tracking (MLflow, Weights & Biases)\n",
                "- Model serialization (save trained models)\n",
                "- CI/CD pipelines for automated training\n",
                "- Model deployment as REST API\n",
                "- Monitoring and retraining strategies\n",
                "\n",
                "---\n",
                "\n",
                "**Congratulations!** üéâ You've completed Week 1 of MLOps learning!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3262be57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# ADDITIONAL EXPERIMENTS (OPTIONAL)\n",
                "# ============================================================================\n",
                "\n",
                "# This cell is left empty for you to experiment with:\n",
                "# - Different hyperparameter ranges\n",
                "# - Other classification algorithms (SVM, Gradient Boosting, etc.)\n",
                "# - Feature engineering ideas\n",
                "# - Different evaluation metrics (precision, recall, F1-score)\n",
                "# - Cross-validation strategies\n",
                "\n",
                "# Example experiments you could try:\n",
                "# 1. Add more hyperparameters to tune (min_samples_split, min_samples_leaf)\n",
                "# 2. Try different scalers (MinMaxScaler, RobustScaler)\n",
                "# 3. Create polynomial features\n",
                "# 4. Visualize decision boundaries\n",
                "# 5. Plot feature importances\n",
                "\n",
                "# Happy experimenting! üöÄ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "lc_agent",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
